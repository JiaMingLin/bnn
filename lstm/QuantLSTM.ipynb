{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jiaming/mambaforge/envs/torch112/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "    def __init__(\n",
       "            self,\n",
       "            input_size: int,\n",
       "            hidden_size: int,\n",
       "            num_layers: int = 1,\n",
       "            bias: Optional[bool] = True,\n",
       "            batch_first: bool = False,\n",
       "            bidirectional: bool = False,\n",
       "            weight_quant=Int8WeightPerTensorFloat,\n",
       "            bias_quant=Int32Bias,\n",
       "            io_quant=Int8ActPerTensorFloat,\n",
       "            gate_acc_quant=Int8ActPerTensorFloat,\n",
       "            sigmoid_quant=Uint8ActPerTensorFloat,\n",
       "            tanh_quant=Int8ActPerTensorFloat,\n",
       "            cell_state_quant=Int8ActPerTensorFloat,\n",
       "            coupled_input_forget_gates: bool = False,\n",
       "            cat_output_cell_states=True,\n",
       "            shared_input_hidden_weights=False,\n",
       "            shared_intra_layer_weight_quant=False,\n",
       "            shared_intra_layer_gate_acc_quant=False,\n",
       "            shared_cell_state_quant=True,\n",
       "            return_quant_tensor: bool = False,\n",
       "            device: Optional[torch.device] = None,\n",
       "            dtype: Optional[torch.dtype] = None,\n",
       "            **kwargs):\n",
       "        super(QuantLSTM, self).__init__(\n",
       "            layer_impl=_QuantLSTMLayer,\n",
       "            input_size=input_size,\n",
       "            hidden_size=hidden_size,\n",
       "            num_layers=num_layers,\n",
       "            bias=bias,\n",
       "            batch_first=batch_first,\n",
       "            bidirectional=bidirectional,\n",
       "            weight_quant=weight_quant,\n",
       "            bias_quant=bias_quant,\n",
       "            io_quant=io_quant,\n",
       "            gate_acc_quant=gate_acc_quant,\n",
       "            sigmoid_quant=sigmoid_quant,\n",
       "            tanh_quant=tanh_quant,\n",
       "            cell_state_quant=cell_state_quant,\n",
       "            cifg=coupled_input_forget_gates,\n",
       "            shared_input_hidden_weights=shared_input_hidden_weights,\n",
       "            shared_intra_layer_weight_quant=shared_intra_layer_weight_quant,\n",
       "            shared_intra_layer_gate_acc_quant=shared_intra_layer_gate_acc_quant,\n",
       "            shared_cell_state_quant=shared_cell_state_quant,\n",
       "            return_quant_tensor=return_quant_tensor,\n",
       "            dtype=dtype,\n",
       "            device=device,\n",
       "            **kwargs)\n",
       "        if cat_output_cell_states and cell_state_quant is not None and not shared_cell_state_quant:\n",
       "            raise RuntimeError(\"Concatenating cell states requires shared cell quantizers.\")\n",
       "        self.cat_output_cell_states = cat_output_cell_states\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import inspect\n",
    "from brevitas.nn import QuantLSTM\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "def pretty_print_source(source):\n",
    "    display(Markdown('```python\\n' + source + '\\n```'))\n",
    "\n",
    "source = inspect.getsource(QuantLSTM.__init__)\n",
    "pretty_print_source(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from IPython.display import IFrame\n",
    "\n",
    "def show_netron(model_path, port):\n",
    "    try:\n",
    "        import netron\n",
    "        time.sleep(3.)\n",
    "        netron.start(model_path, address=(\"localhost\", port), browse=False)\n",
    "        return IFrame(src=f\"http://localhost:{port}/\", width=\"100%\", height=400)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jiaming/mambaforge/envs/torch112/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from brevitas.nn import QuantLSTM\n",
    "from brevitas.export import export_onnx_qcdq\n",
    "\n",
    "quant_lstm_weight_only = QuantLSTM(input_size=10, hidden_size=20, weight_bit_width=4, io_quant=None, bias_quant=None, gate_acc_quant=None, sigmoid_quant=None, tanh_quant=None, cell_state_quant=None)\n",
    "export_path = 'quant_lstm_weight_only_4b.onnx'\n",
    "exported_model = export_onnx_qcdq(quant_lstm_weight_only, (torch.randn(5, 1, 10)), opset_version=14, export_path=export_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://localhost:8080\n",
      "Serving 'quant_lstm_weight_only_4b.onnx' at http://localhost:8080\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8080/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fda16bca7c0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_netron(export_path, 8080)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0;93m2024-06-15 16:16:35.665527411 [W:onnxruntime:, graph.cc:1296 Graph] Initializer onnx::LSTM_103 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n",
      "\u001b[0;93m2024-06-15 16:16:35.665546285 [W:onnxruntime:, graph.cc:1296 Graph] Initializer onnx::Concat_104 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\u001b[m\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "\n",
    "sess = ort.InferenceSession(export_path)\n",
    "input_name = sess.get_inputs()[0].name\n",
    "np_input = np.random.uniform(size=(5, 1, 10)).astype(np.float32)  # (seq_len, batch_size, input_size)\n",
    "pred_onnx = sess.run(None, {input_name: np_input})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from brevitas.nn import QuantLSTM\n",
    "from brevitas.export import export_onnx_qcdq\n",
    "\n",
    "quant_lstm_weight_only_cifg = QuantLSTM(\n",
    "    input_size=10, hidden_size=20, coupled_input_forget_gates=True, weight_bit_width=4,\n",
    "    io_quant=None, bias_quant=None, gate_acc_quant=None, sigmoid_quant=None, tanh_quant=None, cell_state_quant=None)\n",
    "export_path = 'quant_lstm_weight_only_cifg_4b.onnx'\n",
    "exported_model = export_onnx_qcdq(quant_lstm_weight_only_cifg, (torch.randn(5, 1, 10)), opset_version=14, export_path=export_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving 'quant_lstm_weight_only_cifg_4b.onnx' at http://localhost:8082\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8082/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fda157ac520>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_netron(export_path, 8082)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jiaming/mambaforge/envs/torch112/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RescalingIntQuant(\n",
       "  (int_quant): IntQuant(\n",
       "    (float_to_int_impl): RoundSte()\n",
       "    (tensor_clamp_impl): TensorClamp()\n",
       "    (delay_wrapper): DelayWrapper(\n",
       "      (delay_impl): _NoDelay()\n",
       "    )\n",
       "  )\n",
       "  (scaling_impl): ParameterFromRuntimeStatsScaling(\n",
       "    (stats_input_view_shape_impl): OverTensorView()\n",
       "    (stats): _Stats(\n",
       "      (stats_impl): AbsPercentile()\n",
       "    )\n",
       "    (restrict_scaling): _RestrictValue(\n",
       "      (restrict_value_impl): FloatRestrictValue()\n",
       "    )\n",
       "    (clamp_scaling): _ClampValue(\n",
       "      (clamp_min_ste): ScalarClampMinSte()\n",
       "    )\n",
       "    (restrict_inplace_preprocess): Identity()\n",
       "    (restrict_preprocess): Identity()\n",
       "  )\n",
       "  (int_scaling_impl): IntScaling()\n",
       "  (zero_point_impl): ZeroZeroPoint(\n",
       "    (zero_point): StatelessBuffer()\n",
       "  )\n",
       "  (msb_clamp_bit_width_impl): BitWidthConst(\n",
       "    (bit_width): StatelessBuffer()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from brevitas.quant.scaled_int import Int8ActPerTensorFloat, Int8WeightPerTensorFloat\n",
    "Int8ActPerTensorFloat.tensor_quant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RoundSte()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Int8WeightPerTensorFloat.float_to_int_impl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IntScaling()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Int8WeightPerTensorFloat.int_scaling_impl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ScalingImplType.STATS: 'STATS'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Int8WeightPerTensorFloat.scaling_impl_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<FloatToIntImplType.ROUND: 'ROUND'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Int8WeightPerTensorFloat.float_to_int_impl_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IntQuant(\n",
       "  (float_to_int_impl): RoundSte()\n",
       "  (tensor_clamp_impl): TensorClampSte()\n",
       "  (delay_wrapper): DelayWrapper(\n",
       "    (delay_impl): _NoDelay()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Int8WeightPerTensorFloat.int_quant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch112",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
