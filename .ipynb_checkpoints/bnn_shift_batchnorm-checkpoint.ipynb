{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jiaming/mambaforge/envs/brevitas/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'collections.OrderedDict'>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "model_weights = torch.load(\"mnist_bnn_mlp.pt\")\n",
    "print(type(model_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['fc1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'fc2.weight', 'bn2.weight', 'bn2.bias', 'bn2.running_mean', 'bn2.running_var', 'fc3.weight', 'bn3.weight', 'bn3.bias', 'bn3.running_mean', 'bn3.running_var', 'fc4.weight', 'bn4.weight', 'bn4.bias', 'bn4.running_mean', 'bn4.running_var'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_weights.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(293.3531, device='cuda:0') tensor(-324.8379, device='cuda:0')\n",
      "[ 37.03159  172.42488    1.80079  ...   8.453107 -40.55176   81.108574]\n",
      "tensor(155.2061, device='cuda:0') tensor(-168.5288, device='cuda:0')\n",
      "[ 16.096601 -47.398865  19.486797 ...  -8.740652  35.948048  54.753796]\n",
      "tensor(63.3319, device='cuda:0') tensor(-64.5899, device='cuda:0')\n",
      "[ -5.8445506   4.3053637 -46.04132   ... -31.531416  -40.040245\n",
      "  29.539225 ]\n",
      "tensor(60.5287, device='cuda:0') tensor(-18.6065, device='cuda:0')\n",
      "[ -1.4491987  33.85512   -18.60646    16.146376   26.692144   54.546726\n",
      "   8.987974   42.432343   49.04103    60.528675 ]\n"
     ]
    }
   ],
   "source": [
    "for layer in model_weights.items():\n",
    "    if \"running_mean\" in layer[0]:\n",
    "        print(torch.max(layer[1]), torch.min(layer[1]))\n",
    "        print(layer[1].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(66.8029, device='cuda:0') tensor(29.1342, device='cuda:0')\n",
      "tensor(252.5200, device='cuda:0') tensor(105.6245, device='cuda:0')\n",
      "tensor(341.2095, device='cuda:0') tensor(177.9464, device='cuda:0')\n",
      "tensor(483.5791, device='cuda:0') tensor(350.5690, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "epsilon = 1E-5\n",
    "def ap2(x):\n",
    "    return torch.sign(x) * (2**(torch.round(torch.log2(torch.abs(x)))))\n",
    "for layer in model_weights.items():\n",
    "    if \"running_var\" in layer[0]:\n",
    "        appx = ap2(torch.sqrt(layer[1] + epsilon))\n",
    "        print(torch.max(appx), torch.min(appx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1., device='cuda:0') tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(1., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for layer in model_weights.items():\n",
    "    if (\"bn\" in layer[0] and \"weight\" in layer[0]):\n",
    "        print(torch.max(layer[1]), torch.min(layer[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3324, device='cuda:0') tensor(-1.5572, device='cuda:0')\n",
      "tensor(1.0230, device='cuda:0') tensor(-0.9022, device='cuda:0')\n",
      "tensor(0.5496, device='cuda:0') tensor(-0.5417, device='cuda:0')\n",
      "tensor(0.1357, device='cuda:0') tensor(-0.3242, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for layer in model_weights.items():\n",
    "    if (\"bn\" in layer[0] and \"bias\" in layer[0]):\n",
    "        print(torch.max(layer[1]), torch.min(layer[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('fc1.weight', array([[ 0.01848739, -0.01567838, -0.00683846, ...,  0.00686452,\n",
      "        -0.00400866,  0.00258932],\n",
      "       [-0.02740759, -0.02247655, -0.03095721, ..., -0.00295712,\n",
      "         0.00122434, -0.01671785],\n",
      "       [ 0.02815872, -0.00949073, -0.03406036, ..., -0.01409504,\n",
      "         0.0056101 , -0.03354423],\n",
      "       ...,\n",
      "       [ 0.005783  ,  0.03505113, -0.0340974 , ...,  0.03370386,\n",
      "         0.02693659, -0.0209878 ],\n",
      "       [ 0.01236609,  0.02856796, -0.00298807, ...,  0.03354619,\n",
      "         0.03407821,  0.01780757],\n",
      "       [ 0.03193559, -0.02744831,  0.02623576, ...,  0.00481576,\n",
      "         0.01018268,  0.02258725]], dtype=float32))\n",
      "('bn1.weight', array([1., 1., 1., ..., 1., 1., 1.], dtype=float32))\n",
      "('bn1.bias', array([-0.6206854 , -0.62598604,  0.45009336, ..., -0.6545408 ,\n",
      "        0.3296838 , -0.10878175], dtype=float32))\n",
      "('bn1.running_mean', array([ 37.03159 , 172.42488 ,   1.80079 , ...,   8.453107, -40.55176 ,\n",
      "        81.108574], dtype=float32))\n",
      "('bn1.running_var', array([2423.7136, 2107.398 , 3202.1587, ..., 3625.8098, 2962.793 ,\n",
      "       2607.073 ], dtype=float32))\n",
      "('fc2.weight', array([[-0.5643703 ,  0.13081405, -0.16896644, ..., -0.17876725,\n",
      "         0.17517829, -0.5962373 ],\n",
      "       [ 0.2138503 ,  0.28412452, -0.11568355, ..., -0.38667053,\n",
      "        -0.08458731,  0.06034601],\n",
      "       [-0.05332414,  1.2028838 ,  0.24190299, ..., -0.09584522,\n",
      "         0.13063511, -0.10342555],\n",
      "       ...,\n",
      "       [-0.06403908, -0.40888724,  0.17648329, ...,  0.0533307 ,\n",
      "         0.03941674, -0.0070717 ],\n",
      "       [-0.6620983 ,  0.3949918 , -0.17953768, ...,  0.27612635,\n",
      "         0.57653666,  0.4839529 ],\n",
      "       [-0.49284387, -0.00840067, -0.3525687 , ...,  0.27125084,\n",
      "        -0.2564578 ,  0.463943  ]], dtype=float32))\n",
      "('bn2.weight', array([1., 1., 1., ..., 1., 1., 1.], dtype=float32))\n",
      "('bn2.bias', array([0.09571363, 0.27583814, 0.5162938 , ..., 0.57453936, 0.22152121,\n",
      "       0.29359093], dtype=float32))\n",
      "('bn2.running_mean', array([ 16.096601, -47.398865,  19.486797, ...,  -8.740652,  35.948048,\n",
      "        54.753796], dtype=float32))\n",
      "('bn2.running_var', array([22332.951, 22746.752, 23174.164, ..., 63766.363, 22926.506,\n",
      "       24331.186], dtype=float32))\n",
      "('fc3.weight', array([[-0.08097328,  0.22486374,  0.30537316, ...,  0.41611293,\n",
      "         0.7619858 , -0.01413556],\n",
      "       [-0.42216116,  0.33954823,  1.8919151 , ..., -1.0220687 ,\n",
      "        -0.9854351 ,  2.6072855 ],\n",
      "       [-0.40142474,  0.11519126, -0.21131085, ...,  0.58397686,\n",
      "        -0.03746151, -3.8668098 ],\n",
      "       ...,\n",
      "       [-1.8903979 , -1.0896717 ,  1.0877626 , ...,  0.20045006,\n",
      "         4.488191  , -1.2172033 ],\n",
      "       [-0.54320836,  0.16751194,  1.6200337 , ...,  0.10576838,\n",
      "         0.56358695, -0.59009165],\n",
      "       [-0.9317762 ,  0.05490725,  0.5825788 , ...,  1.9325484 ,\n",
      "        -0.04080825,  0.588484  ]], dtype=float32))\n",
      "('bn3.weight', array([1., 1., 1., ..., 1., 1., 1.], dtype=float32))\n",
      "('bn3.bias', array([ 0.05251199,  0.0299988 , -0.2546136 , ..., -0.01948988,\n",
      "       -0.22934593,  0.01528037], dtype=float32))\n",
      "('bn3.running_mean', array([ -5.8445506,   4.3053637, -46.04132  , ..., -31.531416 ,\n",
      "       -40.040245 ,  29.539225 ], dtype=float32))\n",
      "('bn3.running_var', array([91306.69 , 62519.742, 86907.93 , ..., 68498.516, 80674.47 ,\n",
      "       80211.055], dtype=float32))\n",
      "('fc4.weight', array([[ 5.749819 ,  7.38414  ,  5.5269237, ...,  7.1008143,  7.269559 ,\n",
      "         5.652886 ],\n",
      "       [-5.8631988,  5.889067 , -6.9337378, ..., -5.5730424, -6.24957  ,\n",
      "         5.5965066],\n",
      "       [ 7.219995 , -5.8492494,  6.5177345, ...,  6.595915 ,  6.7813478,\n",
      "        -7.7415037],\n",
      "       ...,\n",
      "       [-6.078867 ,  6.0033655, -5.585769 , ..., -5.541348 , -6.292594 ,\n",
      "        -5.66252  ],\n",
      "       [ 4.5930047, -4.882265 , -6.7656245, ...,  6.866807 , -5.0478578,\n",
      "         3.9469721],\n",
      "       [-5.772535 ,  6.1011558, -4.8700447, ..., -7.748255 , -7.7745504,\n",
      "        -6.2273293]], dtype=float32))\n",
      "('bn4.weight', array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32))\n",
      "('bn4.bias', array([ 0.02279236,  0.11162553,  0.07788775,  0.13567808,  0.00952009,\n",
      "       -0.32418838,  0.00979124,  0.12065037, -0.2552636 ,  0.02868043],\n",
      "      dtype=float32))\n",
      "('bn4.running_mean', array([ -1.4491987,  33.85512  , -18.60646  ,  16.146376 ,  26.692144 ,\n",
      "        54.546726 ,   8.987974 ,  42.432343 ,  49.04103  ,  60.528675 ],\n",
      "      dtype=float32))\n",
      "('bn4.running_var', array([137139.  , 155036.75, 123538.66, 205261.28, 215806.78, 135904.16,\n",
      "       164588.6 , 142151.88, 122898.61, 233848.72], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for layer in model_weights.items():\n",
    "#     if \"running_var\" in layer[0]:\n",
    "#         print(ap2(torch.sqrt(layer[1] + epsilon)))\n",
    "    model_weights[layer[0]] = layer[1].cpu().numpy()\n",
    "\n",
    "for layer in model_weights.items():\n",
    "    print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from shift_batchnorm import ShiftBatchNorm\n",
    "\n",
    "class BinaryLinear:\n",
    "    def __init__(self, in_features, out_features):\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = np.zeros([out_features, in_features])\n",
    "        self.binary_weight = np.zeros([out_features, in_features])\n",
    "    \n",
    "    def binarize(self):\n",
    "        self.binary_weight = np.ones(self.weight.shape)\n",
    "        self.binary_weight[self.weight<0] = -1\n",
    "        self.binary_weight = (self.binary_weight + np.ones(self.weight.shape))/2\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        output = np.zeros([1, self.out_features])\n",
    "        for i in range(self.out_features):\n",
    "            row = self.binary_weight[i,:]\n",
    "            xnor = ~np.logical_xor(row, x)\n",
    "            output[0, i] = 2*np.sum(xnor) - self.in_features\n",
    "        return output\n",
    "\n",
    "class BinaryHardTanH:\n",
    "    def __init__(self, in_features):\n",
    "        self.in_features = in_features\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x[x>1] = 1\n",
    "        x[x<-1] = -1\n",
    "        x[x<0] = -1\n",
    "        x[x>=0] = 1\n",
    "        return (x+np.ones(x.shape))/2\n",
    "        \n",
    "        \n",
    "\n",
    "class BinaryNet:\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.features = [\n",
    "            BinaryLinear(784,1024),\n",
    "            ShiftBatchNorm(1024),\n",
    "            BinaryHardTanH(1024),\n",
    "            \n",
    "            BinaryLinear(1024,1024),\n",
    "            ShiftBatchNorm(1024),\n",
    "            BinaryHardTanH(1024),\n",
    "            \n",
    "            BinaryLinear(1024,1024),\n",
    "            ShiftBatchNorm(1024),\n",
    "            BinaryHardTanH(1024),\n",
    "            \n",
    "            BinaryLinear(1024,10),\n",
    "            ShiftBatchNorm(10)\n",
    "        ]\n",
    "    \n",
    "    def load_weight(self, weight):\n",
    "        cnt = 0\n",
    "        \n",
    "        weight = list(weight.items())\n",
    "        for layer in self.features:\n",
    "            (key, value) = weight[cnt]\n",
    "\n",
    "            if isinstance(layer, BinaryHardTanH):\n",
    "                continue\n",
    "            \n",
    "            if layer.weight.shape != value.shape:\n",
    "                print(\"Layer {}, non competible shape, expected: {}, loading: {}\".format(key, layer.weight.shape, value.shape))\n",
    "                raise\n",
    "                \n",
    "            layer.weight = nn.Parameter(torch.tensor(value))\n",
    "            cnt+=1\n",
    "            \n",
    "            if 'bn' in key:\n",
    "                (key, value) = weight[cnt]\n",
    "                layer.bias = nn.Parameter(torch.tensor(value))\n",
    "                \n",
    "                (key, value) = weight[cnt+1]\n",
    "                layer.running_mean = torch.tensor(value)\n",
    "                    \n",
    "                (key, value) = weight[cnt+2]\n",
    "                layer.running_var = torch.tensor(value)\n",
    "                \n",
    "                cnt+=3\n",
    "    \n",
    "    def binarize(self):\n",
    "        for layer in self.features:\n",
    "            if isinstance(layer, BinaryLinear):\n",
    "                layer.binarize()\n",
    "    def __call__(self, x):\n",
    "        \n",
    "        # turn to zero one\n",
    "        x[x<0] = -1; x[x>=0] = 1\n",
    "        x = (x + np.ones(x.shape))/2\n",
    "        \n",
    "        for layer in self.features:\n",
    "            if isinstance(layer, ShiftBatchNorm):\n",
    "                x = torch.tensor(x, dtype=torch.float32)\n",
    "                layer.training = False\n",
    "                x = layer(x)\n",
    "                x = x.detach().numpy()\n",
    "            else:\n",
    "                x = layer(x)\n",
    "        \n",
    "        x = torch.tensor(x, dtype=torch.float32)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnn = BinaryNet()\n",
    "bnn.load_weight(model_weights)\n",
    "bnn.binarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 784)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-2.4816, -2.7430, -1.9387, -0.7859, -4.1983, -2.7895, -3.4251, -2.9499,\n",
       "         -2.6533, -3.8819]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = np.random.uniform(-1,1,[1,784]).astype(np.float32)\n",
    "\n",
    "print(s.shape)\n",
    "bnn(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "\n",
    "dataset2 = datasets.MNIST('../data', train=False,\n",
    "                       transform=transform)\n",
    "test_kwargs = {'batch_size': 1}\n",
    "test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [03:42<00:00, 44.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 93.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "from tqdm import tqdm\n",
    "for data, target in tqdm(test_loader):\n",
    "    data = data.flatten(start_dim=1).numpy()\n",
    "    output = bnn(data)\n",
    "    pred = output.argmax(dim=1, keepdim=True)\n",
    "    correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "print(\"Accuracy = {}\".format(100. * correct / len(test_loader.dataset)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256.0227813720703"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import floor\n",
    "floor(256.02279236*(2**16))/(2**16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2**7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brevitas",
   "language": "python",
   "name": "brevitas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
