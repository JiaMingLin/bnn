{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "torch.manual_seed(0)\n",
    "\n",
    "from torch.nn import Module\n",
    "\n",
    "# import brevitas.nn as qnn\n",
    "from brevitas.nn import QuantLinear, QuantHardTanh, QuantIdentity\n",
    "from brevitas.nn import QuantSigmoid\n",
    "from brevitas import config\n",
    "\n",
    "from common import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantNet(Module):\n",
    "    def __init__(self):\n",
    "        super(QuantNet, self).__init__()\n",
    "\n",
    "        self.fc1 = QuantLinear(784, 128, weight_quant=Int8WeightPerTensorFloatScratch, bias=Int32Bias)\n",
    "        # self.bn1 = nn.BatchNorm1d(128)\n",
    "        #self.bn1 = ShiftBatchNorm(1024)\n",
    "\n",
    "        self.fc2 = QuantLinear(128, 128, weight_quant=Int8WeightPerTensorFloatScratch, bias=Int32Bias)\n",
    "        # self.bn2 = nn.BatchNorm1d(1024)\n",
    "        #self.bn2 = ShiftBatchNorm(1024)\n",
    "\n",
    "        self.fc3 = QuantLinear(128, 128, weight_quant=Int8WeightPerTensorFloatScratch, bias=Int32Bias)\n",
    "        # self.bn3 = nn.BatchNorm1d(128)\n",
    "        #self.bn3 = ShiftBatchNorm(128)\n",
    "\n",
    "        self.fc4 = QuantLinear(128, 10, weight_quant=Int8WeightPerTensorFloatScratch, bias=Int32Bias)\n",
    "        # self.bn4 = nn.BatchNorm1d(128)\n",
    "        #self.bn4 = ShiftBatchNorm(128)\n",
    "        \n",
    "        self.quant_identity = QuantIdentity(act_quant=Int8ActPerTensorFloatScratch, return_quant_tensor = True)\n",
    "        self.quant_act = QuantSigmoid(act_quant=Int8ActPerTensorFloatScratch, return_quant_tensor = True)\n",
    "        self.dropout = nn.Dropout(p=0.0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "\n",
    "        x = self.quant_identity(x)\n",
    "        # x = self.dropout(x)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        # x = self.bn1(x)\n",
    "        x = self.quant_act(x)\n",
    "        # x = self.dropout(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        # x = self.bn2(x)\n",
    "        x = self.quant_act(x)\n",
    "        # x = self.dropout(x)\n",
    "\n",
    "        x = self.fc3(x)\n",
    "        # x = self.bn3(x)\n",
    "        x = self.quant_act(x)\n",
    "        # x = self.dropout(x)\n",
    "\n",
    "        x = self.fc4(x)\n",
    "        # x = self.bn4(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Pre-trained Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0078)\n",
      "Parameter containing:\n",
      "tensor(1., requires_grad=True)\n",
      "tensor(0.0089, grad_fn=<DivBackward0>)\n",
      "Parameter containing:\n",
      "tensor(2.8619, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "config.IGNORE_MISSING_KEYS = True\n",
    "# pretrend weight path = 'mnist_qnn_mlp.pt'\n",
    "model_state_dict = torch.load('mnist_qnn_mlp.pt')\n",
    "net = QuantNet()\n",
    "print(net.quant_act.quant_act_scale())\n",
    "print(net.quant_identity.act_quant.fused_activation_quant_proxy.tensor_quant.scaling_impl.value)\n",
    "net.load_state_dict(model_state_dict)\n",
    "print(net.quant_act.quant_act_scale())\n",
    "print(net.quant_identity.act_quant.fused_activation_quant_proxy.tensor_quant.scaling_impl.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brevitas.core.scaling import ConstScaling\n",
    "\n",
    "from brevitas.inject import ExtendedInjector\n",
    "class CommonQuantizer(ExtendedInjector):\n",
    "    quant_type = QuantType.INT\n",
    "    bit_width_impl_type = BitWidthImplType.CONST\n",
    "    scaling_impl_type = ScalingImplType.CONST\n",
    "    restrict_scaling_type = RestrictValueType.FP\n",
    "    zero_point_impl = ZeroZeroPoint\n",
    "    float_to_int_impl_type = FloatToIntImplType.ROUND\n",
    "    scaling_per_output_channel = False\n",
    "    narrow_range = False\n",
    "    signed = True\n",
    "\n",
    "class ActInferenceQuant(CommonQuantizer, ActQuantSolver):\n",
    "    bit_width = 8\n",
    "    # scaling_impl = ConstScaling(2.8619)\n",
    "    def scaling_impl(self):\n",
    "        return ConstScaling(2.8619)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantNetInference(Module):\n",
    "    def __init__(self):\n",
    "        super(QuantNetInference, self).__init__()\n",
    "\n",
    "        self.fc1 = QuantLinear(784, 128, weight_quant=Int8WeightPerTensorFloatScratch, bias=Int32Bias)\n",
    "        # self.bn1 = nn.BatchNorm1d(128)\n",
    "        #self.bn1 = ShiftBatchNorm(1024)\n",
    "\n",
    "        self.fc2 = QuantLinear(128, 128, weight_quant=Int8WeightPerTensorFloatScratch, bias=Int32Bias)\n",
    "        # self.bn2 = nn.BatchNorm1d(1024)\n",
    "        #self.bn2 = ShiftBatchNorm(1024)\n",
    "\n",
    "        self.fc3 = QuantLinear(128, 128, weight_quant=Int8WeightPerTensorFloatScratch, bias=Int32Bias)\n",
    "        # self.bn3 = nn.BatchNorm1d(128)\n",
    "        #self.bn3 = ShiftBatchNorm(128)\n",
    "\n",
    "        self.fc4 = QuantLinear(128, 10, weight_quant=Int8WeightPerTensorFloatScratch, bias=Int32Bias)\n",
    "        # self.bn4 = nn.BatchNorm1d(128)\n",
    "        #self.bn4 = ShiftBatchNorm(128)\n",
    "        \n",
    "        self.quant_identity = QuantIdentity(act_quant=ActInferenceQuant, return_quant_tensor = True)\n",
    "        self.quant_act = QuantSigmoid(act_quant=ActInferenceQuant, return_quant_tensor = True)\n",
    "        self.dropout = nn.Dropout(p=0.0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "\n",
    "        x = self.quant_identity(x)\n",
    "        # x = self.dropout(x)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        # x = self.bn1(x)\n",
    "        x = self.quant_act(x)\n",
    "        # x = self.dropout(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        # x = self.bn2(x)\n",
    "        x = self.quant_act(x)\n",
    "        # x = self.dropout(x)\n",
    "\n",
    "        x = self.fc3(x)\n",
    "        # x = self.bn3(x)\n",
    "        x = self.quant_act(x)\n",
    "        # x = self.dropout(x)\n",
    "\n",
    "        x = self.fc4(x)\n",
    "        # x = self.bn4(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QuantNetInference(\n",
      "  (fc1): QuantLinear(\n",
      "    in_features=784, out_features=128, bias=False\n",
      "    (input_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "    )\n",
      "    (output_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "    )\n",
      "    (weight_quant): WeightQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "      (tensor_quant): RescalingIntQuant(\n",
      "        (int_quant): IntQuant(\n",
      "          (float_to_int_impl): RoundSte()\n",
      "          (tensor_clamp_impl): TensorClampSte()\n",
      "          (delay_wrapper): DelayWrapper(\n",
      "            (delay_impl): _NoDelay()\n",
      "          )\n",
      "        )\n",
      "        (scaling_impl): StatsFromParameterScaling(\n",
      "          (parameter_list_stats): _ParameterListStats(\n",
      "            (first_tracked_param): _ViewParameterWrapper(\n",
      "              (view_shape_impl): OverTensorView()\n",
      "            )\n",
      "            (stats): _Stats(\n",
      "              (stats_impl): AbsMax()\n",
      "            )\n",
      "          )\n",
      "          (stats_scaling_impl): _StatsScaling(\n",
      "            (affine_rescaling): Identity()\n",
      "            (restrict_clamp_scaling): _RestrictClampValue(\n",
      "              (clamp_min_ste): Identity()\n",
      "              (restrict_value_impl): FloatRestrictValue()\n",
      "            )\n",
      "            (restrict_scaling_pre): Identity()\n",
      "          )\n",
      "        )\n",
      "        (int_scaling_impl): IntScaling()\n",
      "        (zero_point_impl): ZeroZeroPoint(\n",
      "          (zero_point): StatelessBuffer()\n",
      "        )\n",
      "        (msb_clamp_bit_width_impl): BitWidthConst(\n",
      "          (bit_width): StatelessBuffer()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (bias_quant): BiasQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "    )\n",
      "  )\n",
      "  (fc2): QuantLinear(\n",
      "    in_features=128, out_features=128, bias=False\n",
      "    (input_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "    )\n",
      "    (output_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "    )\n",
      "    (weight_quant): WeightQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "      (tensor_quant): RescalingIntQuant(\n",
      "        (int_quant): IntQuant(\n",
      "          (float_to_int_impl): RoundSte()\n",
      "          (tensor_clamp_impl): TensorClampSte()\n",
      "          (delay_wrapper): DelayWrapper(\n",
      "            (delay_impl): _NoDelay()\n",
      "          )\n",
      "        )\n",
      "        (scaling_impl): StatsFromParameterScaling(\n",
      "          (parameter_list_stats): _ParameterListStats(\n",
      "            (first_tracked_param): _ViewParameterWrapper(\n",
      "              (view_shape_impl): OverTensorView()\n",
      "            )\n",
      "            (stats): _Stats(\n",
      "              (stats_impl): AbsMax()\n",
      "            )\n",
      "          )\n",
      "          (stats_scaling_impl): _StatsScaling(\n",
      "            (affine_rescaling): Identity()\n",
      "            (restrict_clamp_scaling): _RestrictClampValue(\n",
      "              (clamp_min_ste): Identity()\n",
      "              (restrict_value_impl): FloatRestrictValue()\n",
      "            )\n",
      "            (restrict_scaling_pre): Identity()\n",
      "          )\n",
      "        )\n",
      "        (int_scaling_impl): IntScaling()\n",
      "        (zero_point_impl): ZeroZeroPoint(\n",
      "          (zero_point): StatelessBuffer()\n",
      "        )\n",
      "        (msb_clamp_bit_width_impl): BitWidthConst(\n",
      "          (bit_width): StatelessBuffer()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (bias_quant): BiasQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "    )\n",
      "  )\n",
      "  (fc3): QuantLinear(\n",
      "    in_features=128, out_features=128, bias=False\n",
      "    (input_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "    )\n",
      "    (output_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "    )\n",
      "    (weight_quant): WeightQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "      (tensor_quant): RescalingIntQuant(\n",
      "        (int_quant): IntQuant(\n",
      "          (float_to_int_impl): RoundSte()\n",
      "          (tensor_clamp_impl): TensorClampSte()\n",
      "          (delay_wrapper): DelayWrapper(\n",
      "            (delay_impl): _NoDelay()\n",
      "          )\n",
      "        )\n",
      "        (scaling_impl): StatsFromParameterScaling(\n",
      "          (parameter_list_stats): _ParameterListStats(\n",
      "            (first_tracked_param): _ViewParameterWrapper(\n",
      "              (view_shape_impl): OverTensorView()\n",
      "            )\n",
      "            (stats): _Stats(\n",
      "              (stats_impl): AbsMax()\n",
      "            )\n",
      "          )\n",
      "          (stats_scaling_impl): _StatsScaling(\n",
      "            (affine_rescaling): Identity()\n",
      "            (restrict_clamp_scaling): _RestrictClampValue(\n",
      "              (clamp_min_ste): Identity()\n",
      "              (restrict_value_impl): FloatRestrictValue()\n",
      "            )\n",
      "            (restrict_scaling_pre): Identity()\n",
      "          )\n",
      "        )\n",
      "        (int_scaling_impl): IntScaling()\n",
      "        (zero_point_impl): ZeroZeroPoint(\n",
      "          (zero_point): StatelessBuffer()\n",
      "        )\n",
      "        (msb_clamp_bit_width_impl): BitWidthConst(\n",
      "          (bit_width): StatelessBuffer()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (bias_quant): BiasQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "    )\n",
      "  )\n",
      "  (fc4): QuantLinear(\n",
      "    in_features=128, out_features=10, bias=False\n",
      "    (input_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "    )\n",
      "    (output_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "    )\n",
      "    (weight_quant): WeightQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "      (tensor_quant): RescalingIntQuant(\n",
      "        (int_quant): IntQuant(\n",
      "          (float_to_int_impl): RoundSte()\n",
      "          (tensor_clamp_impl): TensorClampSte()\n",
      "          (delay_wrapper): DelayWrapper(\n",
      "            (delay_impl): _NoDelay()\n",
      "          )\n",
      "        )\n",
      "        (scaling_impl): StatsFromParameterScaling(\n",
      "          (parameter_list_stats): _ParameterListStats(\n",
      "            (first_tracked_param): _ViewParameterWrapper(\n",
      "              (view_shape_impl): OverTensorView()\n",
      "            )\n",
      "            (stats): _Stats(\n",
      "              (stats_impl): AbsMax()\n",
      "            )\n",
      "          )\n",
      "          (stats_scaling_impl): _StatsScaling(\n",
      "            (affine_rescaling): Identity()\n",
      "            (restrict_clamp_scaling): _RestrictClampValue(\n",
      "              (clamp_min_ste): Identity()\n",
      "              (restrict_value_impl): FloatRestrictValue()\n",
      "            )\n",
      "            (restrict_scaling_pre): Identity()\n",
      "          )\n",
      "        )\n",
      "        (int_scaling_impl): IntScaling()\n",
      "        (zero_point_impl): ZeroZeroPoint(\n",
      "          (zero_point): StatelessBuffer()\n",
      "        )\n",
      "        (msb_clamp_bit_width_impl): BitWidthConst(\n",
      "          (bit_width): StatelessBuffer()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (bias_quant): BiasQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "    )\n",
      "  )\n",
      "  (quant_identity): QuantIdentity(\n",
      "    (input_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "    )\n",
      "    (act_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "      (fused_activation_quant_proxy): FusedActivationQuantProxy(\n",
      "        (activation_impl): Identity()\n",
      "        (tensor_quant): RescalingIntQuant(\n",
      "          (int_quant): IntQuant(\n",
      "            (float_to_int_impl): RoundSte()\n",
      "            (tensor_clamp_impl): TensorClamp()\n",
      "            (delay_wrapper): DelayWrapper(\n",
      "              (delay_impl): _NoDelay()\n",
      "            )\n",
      "          )\n",
      "          (scaling_impl): ConstScaling(\n",
      "            (restrict_clamp_scaling): _RestrictClampValue(\n",
      "              (clamp_min_ste): Identity()\n",
      "              (restrict_value_impl): Identity()\n",
      "            )\n",
      "            (value): StatelessBuffer()\n",
      "          )\n",
      "          (int_scaling_impl): IntScaling()\n",
      "          (zero_point_impl): ZeroZeroPoint(\n",
      "            (zero_point): StatelessBuffer()\n",
      "          )\n",
      "          (msb_clamp_bit_width_impl): BitWidthConst(\n",
      "            (bit_width): StatelessBuffer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (quant_act): QuantSigmoid(\n",
      "    (input_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "    )\n",
      "    (act_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "      (fused_activation_quant_proxy): FusedActivationQuantProxy(\n",
      "        (activation_impl): Sigmoid()\n",
      "        (tensor_quant): RescalingIntQuant(\n",
      "          (int_quant): IntQuant(\n",
      "            (float_to_int_impl): RoundSte()\n",
      "            (tensor_clamp_impl): TensorClamp()\n",
      "            (delay_wrapper): DelayWrapper(\n",
      "              (delay_impl): _NoDelay()\n",
      "            )\n",
      "          )\n",
      "          (scaling_impl): ConstScaling(\n",
      "            (restrict_clamp_scaling): _RestrictClampValue(\n",
      "              (clamp_min_ste): Identity()\n",
      "              (restrict_value_impl): Identity()\n",
      "            )\n",
      "            (value): StatelessBuffer()\n",
      "          )\n",
      "          (int_scaling_impl): IntScaling()\n",
      "          (zero_point_impl): ZeroZeroPoint(\n",
      "            (zero_point): StatelessBuffer()\n",
      "          )\n",
      "          (msb_clamp_bit_width_impl): BitWidthConst(\n",
      "            (bit_width): StatelessBuffer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "quant_model_inference = QuantNetInference()\n",
    "print(quant_model_inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before loading\n",
      "tensor(0.0224)\n",
      "tensor(2.8619)\n",
      "after loading\n",
      "tensor(0.0224)\n",
      "tensor(2.8619)\n"
     ]
    }
   ],
   "source": [
    "config.IGNORE_MISSING_KEYS = False\n",
    "# pretrend weight path = 'mnist_qnn_mlp.pt'\n",
    "model_state_dict = torch.load('mnist_qnn_mlp.pt')\n",
    "print(\"before loading\")\n",
    "print(quant_model_inference.quant_act.quant_act_scale())\n",
    "print(quant_model_inference.quant_identity.act_quant.fused_activation_quant_proxy.tensor_quant.scaling_impl(torch.empty(1)))\n",
    "\n",
    "quant_model_inference.load_state_dict(model_state_dict)\n",
    "print(\"after loading\")\n",
    "print(quant_model_inference.quant_act.quant_act_scale())\n",
    "print(quant_model_inference.quant_identity.act_quant.fused_activation_quant_proxy.tensor_quant.scaling_impl(torch.empty(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('fc1.weight',\n",
       "              tensor([[ 0.1019,  0.0678,  0.0766,  ...,  0.0903,  0.0795,  0.0861],\n",
       "                      [-0.0046,  0.0003, -0.0082,  ...,  0.0198,  0.0240,  0.0061],\n",
       "                      [ 0.1158,  0.0782,  0.0536,  ...,  0.0736,  0.0933,  0.0541],\n",
       "                      ...,\n",
       "                      [ 0.0743,  0.1022,  0.0996,  ...,  0.1298,  0.0750,  0.0712],\n",
       "                      [ 0.2434,  0.1943,  0.2404,  ...,  0.1941,  0.1990,  0.2293],\n",
       "                      [ 0.1188,  0.1672,  0.1120,  ...,  0.1572,  0.1394,  0.1312]],\n",
       "                     device='cuda:0')),\n",
       "             ('fc2.weight',\n",
       "              tensor([[-0.3910, -0.1140, -0.2444,  ..., -0.1273, -0.1737,  0.0166],\n",
       "                      [ 0.0476, -0.8722,  0.6388,  ..., -0.4184,  0.1209, -0.1012],\n",
       "                      [ 0.2996,  0.0529,  0.2631,  ...,  0.0447, -0.9385, -0.0182],\n",
       "                      ...,\n",
       "                      [-0.5761,  0.0806, -0.9951,  ..., -0.5898,  0.2716,  0.0159],\n",
       "                      [-0.9280,  0.0778, -0.2498,  ..., -0.3046,  0.0520,  0.1608],\n",
       "                      [ 0.1754,  0.1324,  0.2641,  ...,  0.4492, -0.1247, -0.0627]],\n",
       "                     device='cuda:0')),\n",
       "             ('fc3.weight',\n",
       "              tensor([[-0.0029, -0.0226,  0.2763,  ..., -0.0279,  0.6133, -0.1217],\n",
       "                      [-0.1379, -0.3314, -0.3047,  ...,  0.4043,  0.2286, -0.3942],\n",
       "                      [ 0.0763,  0.1335,  0.1369,  ..., -0.5996, -0.1233,  0.3170],\n",
       "                      ...,\n",
       "                      [ 0.1061,  0.3247, -0.0109,  ..., -0.3436, -0.2747, -0.2203],\n",
       "                      [ 0.0165, -0.6417, -0.5800,  ...,  0.0877,  0.1140, -0.1423],\n",
       "                      [-0.0071,  0.2726, -0.4759,  ..., -0.2581, -0.1705,  0.7474]],\n",
       "                     device='cuda:0')),\n",
       "             ('fc4.weight',\n",
       "              tensor([[-0.4055, -0.5120,  0.2964,  ..., -0.1452, -0.1688,  0.4505],\n",
       "                      [ 0.3097,  0.0612, -0.0783,  ..., -0.5523, -0.4602,  0.1153],\n",
       "                      [ 0.1247,  0.1922,  0.1444,  ..., -0.0047,  0.2528,  0.1371],\n",
       "                      ...,\n",
       "                      [-0.0714,  0.2055,  0.0561,  ...,  0.3600,  0.1064, -0.3459],\n",
       "                      [-0.1356,  0.3290, -0.1969,  ..., -0.5130,  0.3691,  0.0370],\n",
       "                      [-0.3920, -0.1905, -0.4054,  ...,  0.1734, -0.3494,  0.5073]],\n",
       "                     device='cuda:0')),\n",
       "             ('quant_identity.act_quant.fused_activation_quant_proxy.tensor_quant.scaling_impl.value',\n",
       "              tensor(2.8619, device='cuda:0')),\n",
       "             ('quant_act.act_quant.fused_activation_quant_proxy.tensor_quant.scaling_impl.value',\n",
       "              tensor(1.1363, device='cuda:0'))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch112",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
